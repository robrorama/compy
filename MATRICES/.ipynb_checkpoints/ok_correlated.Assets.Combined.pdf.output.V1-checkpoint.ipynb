{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64e8cf3b-d01e-4c0e-a7d8-29600ce6d6f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SPY data from data/2024-11-24/SPY.csv\n",
      "Downloading IWM data and saving to data/2024-11-24/IWM.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading QQQ data and saving to data/2024-11-24/QQQ.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# Create a folder for today's date\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "data_folder = f\"data/{today}\"\n",
    "output_folder = f\"output/{today}\"\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to download or load cached data\n",
    "def get_data(ticker):\n",
    "    file_path = f\"{data_folder}/{ticker}.csv\"\n",
    "    \n",
    "    # Check if file already exists\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Loading {ticker} data from {file_path}\")\n",
    "        try:\n",
    "            return pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading cached file for {ticker}: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Downloading {ticker} data and saving to {file_path}\")\n",
    "        try:\n",
    "            df = yf.download(ticker, period='5y')\n",
    "            if not df.empty:\n",
    "                df.to_csv(file_path)\n",
    "                return df\n",
    "            else:\n",
    "                print(f\"Downloaded data for {ticker} is empty, skipping.\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {ticker}: {e}\")\n",
    "            return None\n",
    "\n",
    "# List of ETFs and Commodities\n",
    "assets = ['SPY', 'USO']\n",
    "\n",
    "commodities = ['CL=F', 'BZ=F']\n",
    "\n",
    "# Combine assets and commodities\n",
    "#all_assets = assets + commodities\n",
    "#all_assets = current_assets\n",
    "\n",
    "all_assets = [ 'SPY', 'IWM', 'QQQ' ]\n",
    "\n",
    "all_assets_Original = [\n",
    "    'SPY', 'USO', 'GC=F', 'TLT', 'XLU', 'XLK', 'XLY', 'DBC', 'EEM', 'ZROZ', \n",
    "    'IEF', 'XLP', 'XLRE', 'PDBC', 'GSG', 'DBA', 'JJM', 'COPX', 'TIP', 'UUP', \n",
    "    'ITB', 'EFA', 'VWO', 'XLC', 'XLV', 'XLF', 'XLI', 'XLB', 'XLE', 'XLRE', \n",
    "    'XLP', 'XLY', 'XLK', 'XLU', 'FXE', 'FXY', 'FXB', 'FXC', 'FXA', 'FXF', 'CNY',\n",
    "    'CL=F', 'BZ=F', 'NG=F', 'RB=F', 'HO=F', 'GC=F', 'SI=F', 'HG=F', \n",
    "    'PL=F', 'PA=F', 'ALI=F', 'ZC=F', 'ZW=F', 'ZS=F', 'KC=F', 'SB=F', \n",
    "    'CT=F', 'CC=F', 'LB=F', 'LE=F', 'HE=F', 'GF=F'\n",
    "]\n",
    "\n",
    "\n",
    "# Function to download or load data for all assets in parallel\n",
    "def download_data_parallel(assets):\n",
    "    df_dict = {}\n",
    "    failed_tickers = []\n",
    "    with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "        future_to_ticker = {executor.submit(get_data, asset): asset for asset in assets}\n",
    "        for future in as_completed(future_to_ticker):\n",
    "            asset = future_to_ticker[future]\n",
    "            try:\n",
    "                df = future.result()\n",
    "                if df is not None and 'Adj Close' in df.columns:\n",
    "                    df_dict[asset] = df['Adj Close']\n",
    "                else:\n",
    "                    print(f\"Data for {asset} is invalid or missing 'Adj Close', skipping.\")\n",
    "                    failed_tickers.append(asset)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {asset}: {e}\")\n",
    "                failed_tickers.append(asset)\n",
    "    if failed_tickers:\n",
    "        print(f\"Failed to download data for: {', '.join(failed_tickers)}\")\n",
    "    return df_dict\n",
    "\n",
    "df_dict = download_data_parallel(all_assets)\n",
    "\n",
    "# Ensure we have valid data before continuing\n",
    "if len(df_dict) == 0:\n",
    "    print(\"No valid data was downloaded, exiting...\")\n",
    "else:\n",
    "    # Calculate percentage change for all assets\n",
    "    pct_change_dict = {}\n",
    "    for asset, df in df_dict.items():\n",
    "        if not df.empty:\n",
    "            pct_change = df.pct_change().dropna()\n",
    "            if not pct_change.empty:\n",
    "                pct_change_dict[asset] = pct_change\n",
    "\n",
    "    # Convert to DataFrame for easier handling\n",
    "    combined_pct_change_df = pd.DataFrame(pct_change_dict).dropna()\n",
    "\n",
    "    # Check if the combined DataFrame is still valid\n",
    "    if combined_pct_change_df.empty:\n",
    "        print(\"No valid percentage change data, exiting...\")\n",
    "    else:\n",
    "        # Save all figures into a single PDF\n",
    "        with PdfPages(f\"{output_folder}/combined_plots.pdf\") as pdf:\n",
    "\n",
    "            # 1. Pair Plot with KDE\n",
    "            g = sns.pairplot(combined_pct_change_df, diag_kind='kde')\n",
    "            g.fig.suptitle('Pair Plot of Percentage Changes Across All Assets', y=1.02)\n",
    "            pdf.savefig(g.fig)  # Save the figure to the PDF\n",
    "            plt.close(g.fig)\n",
    "\n",
    "            # 2. Correlation Heatmap\n",
    "            def plot_correlation_heatmap(combined_pct_change_df):\n",
    "                corr_matrix = combined_pct_change_df.corr()\n",
    "                plt.figure(figsize=(16, 12))\n",
    "                sns.heatmap(corr_matrix, annot=True, cmap='RdBu', center=0, \n",
    "                            annot_kws={\"size\": 8}, fmt='.2f', cbar_kws={\"shrink\": 0.8})\n",
    "                plt.xticks(rotation=45, ha=\"right\", fontsize=8)\n",
    "                plt.yticks(fontsize=8)\n",
    "                plt.title('Correlation Heatmap of Percentage Changes Across All Assets')\n",
    "                pdf.savefig()  # Save the heatmap to the PDF\n",
    "                plt.close()\n",
    "\n",
    "            plot_correlation_heatmap(combined_pct_change_df)\n",
    "\n",
    "            # 3. Time Series Overlay\n",
    "            def plot_time_series_grid(combined_pct_change_df, assets, num_cols=3):\n",
    "                num_plots = len(assets) * (len(assets) - 1) // 2\n",
    "                num_rows = (num_plots // num_cols) + 1\n",
    "                fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 10))\n",
    "                axes = axes.flatten()\n",
    "                plot_idx = 0\n",
    "                for i, asset1 in enumerate(assets):\n",
    "                    for asset2 in assets[i+1:]:\n",
    "                        if asset1 in combined_pct_change_df.columns and asset2 in combined_pct_change_df.columns:\n",
    "                            axes[plot_idx].plot(combined_pct_change_df.index, combined_pct_change_df[asset1], label=f'{asset1}', color='blue')\n",
    "                            axes[plot_idx].plot(combined_pct_change_df.index, combined_pct_change_df[asset2], label=f'{asset2}', color='orange')\n",
    "                            axes[plot_idx].set_title(f'{asset1} vs {asset2}')\n",
    "                            axes[plot_idx].legend()\n",
    "                            plot_idx += 1\n",
    "                            if plot_idx >= len(axes):\n",
    "                                break\n",
    "                    if plot_idx >= len(axes):\n",
    "                        break\n",
    "                plt.tight_layout()\n",
    "                pdf.savefig(fig)  # Save to the PDF\n",
    "                plt.close(fig)\n",
    "\n",
    "            plot_time_series_grid(combined_pct_change_df, all_assets)\n",
    "\n",
    "            # 4. Ratio Analysis\n",
    "            def plot_ratio_grid(df_dict, assets, num_cols=3):\n",
    "                num_plots = len(assets) * (len(assets) - 1) // 2\n",
    "                num_rows = (num_plots // num_cols) + 1\n",
    "                fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 10))\n",
    "                axes = axes.flatten()\n",
    "                plot_idx = 0\n",
    "                for i, asset1 in enumerate(assets):\n",
    "                    for asset2 in assets[i+1:]:\n",
    "                        if asset1 in df_dict and asset2 in df_dict:\n",
    "                            ratio = df_dict[asset1] / df_dict[asset2]\n",
    "                            ratio.plot(ax=axes[plot_idx])\n",
    "                            axes[plot_idx].set_title(f'{asset1}/{asset2}')\n",
    "                            plot_idx += 1\n",
    "                            if plot_idx >= len(axes):\n",
    "                                break\n",
    "                    if plot_idx >= len(axes):\n",
    "                        break\n",
    "                plt.tight_layout()\n",
    "                pdf.savefig(fig)  # Save to the PDF\n",
    "                plt.close(fig)\n",
    "\n",
    "            plot_ratio_grid(df_dict, all_assets)\n",
    "\n",
    "            # 5. Rolling Correlation Plot\n",
    "            def plot_rolling_corr_grid(combined_pct_change_df, assets, num_cols=3):\n",
    "                num_plots = len(assets) * (len(assets) - 1) // 2\n",
    "                num_rows = (num_plots // num_cols) + 1\n",
    "                fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 10))\n",
    "                axes = axes.flatten()\n",
    "                plot_idx = 0\n",
    "                for i, asset1 in enumerate(assets):\n",
    "                    for asset2 in assets[i+1:]:\n",
    "                        if asset1 in combined_pct_change_df.columns and asset2 in combined_pct_change_df.columns:\n",
    "                            rolling_corr = combined_pct_change_df[asset1].rolling(window=30).corr(combined_pct_change_df[asset2])\n",
    "                            rolling_corr.plot(ax=axes[plot_idx])\n",
    "                            axes[plot_idx].set_title(f'{asset1} vs {asset2} (Rolling Corr)')\n",
    "                            plot_idx += 1\n",
    "                            if plot_idx >= len(axes):\n",
    "                                break\n",
    "                    if plot_idx >= len(axes):\n",
    "                        break\n",
    "                plt.tight_layout()\n",
    "                pdf.savefig(fig)  # Save to the PDF\n",
    "                plt.close(fig)\n",
    "\n",
    "            plot_rolling_corr_grid(combined_pct_change_df, all_assets)\n",
    "\n",
    "            # 6. Ratio Comparisons\n",
    "            def plot_ratio_comparisons_grid(df_dict, assets, num_cols=3):\n",
    "                num_plots = len(assets) * (len(assets) - 1) // 2\n",
    "                num_rows = (num_plots // num_cols) + 1\n",
    "                fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 10))\n",
    "                axes = axes.flatten()\n",
    "                plot_idx = 0\n",
    "                for i, asset1 in enumerate(assets):\n",
    "                    for asset2 in assets[i+1:]:\n",
    "                        if asset1 in df_dict and asset2 in df_dict:\n",
    "                            ratio = df_dict[asset1] / df_dict[asset2]\n",
    "                            ratio.plot(ax=axes[plot_idx])\n",
    "                            axes[plot_idx].set_title(f'{asset1} / {asset2}')\n",
    "                            plot_idx += 1\n",
    "                            if plot_idx >= len(axes):\n",
    "                                break\n",
    "                    if plot_idx >= len(axes):\n",
    "                        break\n",
    "                plt.tight_layout()\n",
    "                pdf.savefig(fig)  # Save to the PDF\n",
    "                plt.close(fig)\n",
    "\n",
    "            plot_ratio_comparisons_grid(df_dict, all_assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe7f7e75-2986-47f1-863f-8f657a0f5f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SPY data from data/2024-11-24/SPY.csv\n",
      "Loading IWM data from data/2024-11-24/IWM.csv\n",
      "Loading QQQ data from data/2024-11-24/QQQ.csv\n",
      "Correlation matrix saved to output/2024-11-24/correlation_matrix.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# Create a folder for today's date\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "data_folder = f\"data/{today}\"\n",
    "output_folder = f\"output/{today}\"\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to download or load cached data\n",
    "def get_data(ticker):\n",
    "    file_path = f\"{data_folder}/{ticker}.csv\"\n",
    "    \n",
    "    # Check if file already exists\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Loading {ticker} data from {file_path}\")\n",
    "        try:\n",
    "            return pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading cached file for {ticker}: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Downloading {ticker} data and saving to {file_path}\")\n",
    "        try:\n",
    "            df = yf.download(ticker, period='5y')\n",
    "            if not df.empty:\n",
    "                df.to_csv(file_path)\n",
    "                return df\n",
    "            else:\n",
    "                print(f\"Downloaded data for {ticker} is empty, skipping.\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {ticker}: {e}\")\n",
    "            return None\n",
    "\n",
    "# List of assets\n",
    "all_assets_orig = [\n",
    "    'SPY', 'USO', 'GC=F', 'TLT', 'XLU', 'XLK', 'XLY', 'DBC', 'EEM', 'ZROZ', \n",
    "    'IEF', 'XLP', 'XLRE', 'PDBC', 'GSG', 'DBA', 'JJM', 'COPX', 'TIP', 'UUP', \n",
    "    'ITB', 'EFA', 'VWO', 'XLC', 'XLV', 'XLF', 'XLI', 'XLB', 'XLE', 'XLRE', \n",
    "    'XLP', 'XLY', 'XLK', 'XLU', 'FXE', 'FXY', 'FXB', 'FXC', 'FXA', 'FXF', \n",
    "    'CNY', 'CL=F', 'BZ=F', 'NG=F', 'RB=F', 'HO=F', 'GC=F', 'SI=F', 'HG=F', \n",
    "    'PL=F', 'PA=F', 'ALI=F', 'ZC=F', 'ZW=F', 'ZS=F', 'KC=F', 'SB=F', \n",
    "    'CT=F', 'CC=F', 'LB=F', 'LE=F', 'HE=F', 'GF=F'\n",
    "]\n",
    "\n",
    "# Function to download or load data for all assets in parallel\n",
    "def download_data_parallel(assets):\n",
    "    df_dict = {}\n",
    "    failed_tickers = []\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        future_to_ticker = {executor.submit(get_data, asset): asset for asset in assets}\n",
    "        for future in as_completed(future_to_ticker):\n",
    "            asset = future_to_ticker[future]\n",
    "            try:\n",
    "                df = future.result()\n",
    "                if df is not None and 'Adj Close' in df.columns:\n",
    "                    df_dict[asset] = df['Adj Close']\n",
    "                else:\n",
    "                    print(f\"Data for {asset} is invalid or missing 'Adj Close', skipping.\")\n",
    "                    failed_tickers.append(asset)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {asset}: {e}\")\n",
    "                failed_tickers.append(asset)\n",
    "    if failed_tickers:\n",
    "        print(f\"Failed to download data for: {', '.join(failed_tickers)}\")\n",
    "    return df_dict\n",
    "\n",
    "df_dict = download_data_parallel(all_assets)\n",
    "\n",
    "# Ensure we have valid data before continuing\n",
    "if len(df_dict) == 0:\n",
    "    print(\"No valid data was downloaded, exiting...\")\n",
    "else:\n",
    "    # Calculate percentage change for all assets\n",
    "    pct_change_dict = {}\n",
    "    for asset, df in df_dict.items():\n",
    "        if not df.empty:\n",
    "            pct_change = df.pct_change().dropna()\n",
    "            if not pct_change.empty:\n",
    "                pct_change_dict[asset] = pct_change\n",
    "\n",
    "    # Convert to DataFrame for easier handling\n",
    "    combined_pct_change_df = pd.DataFrame(pct_change_dict).dropna()\n",
    "\n",
    "    # Check if the combined DataFrame is still valid\n",
    "    if combined_pct_change_df.empty:\n",
    "        print(\"No valid percentage change data, exiting...\")\n",
    "    else:\n",
    "        # Save correlation heatmap to a PDF\n",
    "        with PdfPages(f\"{output_folder}/correlation_matrix.pdf\") as pdf:\n",
    "            def plot_correlation_heatmap(combined_pct_change_df):\n",
    "                corr_matrix = combined_pct_change_df.corr()\n",
    "                plt.figure(figsize=(16, 12))\n",
    "                sns.heatmap(corr_matrix, annot=True, cmap='RdBu', center=0, \n",
    "                            annot_kws={\"size\": 8}, fmt='.2f', cbar_kws={\"shrink\": 0.8})\n",
    "                plt.xticks(rotation=45, ha=\"right\", fontsize=8)\n",
    "                plt.yticks(fontsize=8)\n",
    "                plt.title('Correlation Heatmap of Percentage Changes Across All Assets')\n",
    "                pdf.savefig()  # Save the heatmap to the PDF\n",
    "                plt.close()\n",
    "\n",
    "            plot_correlation_heatmap(combined_pct_change_df)\n",
    "\n",
    "        print(f\"Correlation matrix saved to {output_folder}/correlation_matrix.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7eef8d39-67e9-41c7-b608-a1cc371b5367",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlu_tickers = [\n",
    "    \"NEE\", # NextEra Energy\n",
    "    \"DUK\", # Duke Energy\n",
    "    \"SO\",  # Southern Company\n",
    "    \"D\",   # Dominion Energy\n",
    "    \"AEP\", # American Electric Power\n",
    "    \"EXC\", # Exelon\n",
    "    \"PEG\", # Public Service Enterprise Group\n",
    "    \"ED\",  # Consolidated Edison\n",
    "    \"SRE\", # Sempra Energy\n",
    "    \"WEC\", # WEC Energy Group\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90ba7eef-4c98-4700-af6d-80b79b7501c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlb_tickers = [\n",
    "    \"LIN\",  # Linde plc\n",
    "    \"APD\",  # Air Products and Chemicals\n",
    "    \"SHW\",  # Sherwin-Williams\n",
    "    \"PPG\",  # PPG Industries\n",
    "    \"DOW\",  # Dow Inc.\n",
    "    \"LYB\",  # LyondellBasell Industries\n",
    "    \"ECL\",  # Ecolab\n",
    "    \"FCX\",  # Freeport-McMoRan\n",
    "    \"NEM\",  # Newmont\n",
    "    \"IFF\",  # International Flavors & Fragrances\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5525bcaf-afd8-434e-9b1e-e9a24afa0a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlre_tickers = [\n",
    "    \"PLD\",  # Prologis\n",
    "    \"EQIX\", # Equinix\n",
    "    \"AMT\",  # American Tower\n",
    "    \"CCI\",  # Crown Castle International\n",
    "    \"WELL\", # Welltower\n",
    "    \"AVB\",  # AvalonBay Communities\n",
    "    \"PSA\",  # Public Storage\n",
    "    \"SPG\",  # Simon Property Group\n",
    "    \"VTR\",  # Ventas\n",
    "    \"WY\",   # Weyerhaeuser\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da37eba8-3a48-4455-a785-665fd3b6558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xli_tickers = [\n",
    "    \"UNP\",  # Union Pacific\n",
    "    \"HON\",  # Honeywell International\n",
    "    \"RTX\",  # Raytheon Technologies\n",
    "    \"BA\",   # Boeing\n",
    "    \"CAT\",  # Caterpillar\n",
    "    \"GE\",   # General Electric\n",
    "    \"MMM\",  # 3M\n",
    "    \"CSX\",  # CSX Corporation\n",
    "    \"DE\",   # Deere & Company\n",
    "    \"LMT\",  # Lockheed Martin\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6381940f-676c-414e-bbca-d078f65e373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlv_tickers = [\n",
    "    \"JNJ\",  # Johnson & Johnson\n",
    "    \"UNH\",  # UnitedHealth Group\n",
    "    \"LLY\",  # Eli Lilly and Company\n",
    "    \"MRK\",  # Merck & Co.\n",
    "    \"ABBV\", # AbbVie\n",
    "    \"PFE\",  # Pfizer\n",
    "    \"TMO\",  # Thermo Fisher Scientific\n",
    "    \"ABT\",  # Abbott Laboratories\n",
    "    \"BMY\",  # Bristol-Myers Squibb\n",
    "    \"MDT\",  # Medtronic\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d235fd2b-9322-48de-8cf5-7386cf591c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlf_tickers = [\n",
    "    \"BRK-B\", # Berkshire Hathaway\n",
    "    \"JPM\",   # JPMorgan Chase\n",
    "    \"BAC\",   # Bank of America\n",
    "    \"WFC\",   # Wells Fargo\n",
    "    \"BLK\",   # BlackRock\n",
    "    \"MS\",    # Morgan Stanley\n",
    "    \"GS\",    # Goldman Sachs\n",
    "    \"C\",     # Citigroup\n",
    "    \"USB\",   # U.S. Bancorp\n",
    "    \"PNC\",   # PNC Financial Services\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8707a211-d4c0-48d8-9bf7-0f838a311e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlk_tickers = [\n",
    "    \"AAPL\",  # Apple\n",
    "    \"MSFT\",  # Microsoft\n",
    "    \"NVDA\",  # NVIDIA\n",
    "    \"TSM\",   # Taiwan Semiconductor\n",
    "    \"META\",  # Meta Platforms (formerly Facebook)\n",
    "    \"AVGO\",  # Broadcom\n",
    "    \"ADBE\",  # Adobe\n",
    "    \"TXN\",   # Texas Instruments\n",
    "    \"CRM\",   # Salesforce\n",
    "    \"INTC\",  # Intel\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "569e81c7-21f1-425a-a169-51bb05d716d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xle_tickers = [\n",
    "    \"LNG\",   # Nat Gas\n",
    "    \"XOM\",   # Exxon Mobil\n",
    "    \"CVX\",   # Chevron\n",
    "    \"COP\",   # ConocoPhillips\n",
    "    \"EOG\",   # EOG Resources\n",
    "    \"SLB\",   # Schlumberger\n",
    "    \"VLO\",   # Valero Energy\n",
    "    \"MPC\",   # Marathon Petroleum\n",
    "    \"PSX\",   # Phillips 66\n",
    "    \"OXY\",   # Occidental Petroleum\n",
    "    \"HAL\",   # Halliburton\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c24b855-57fc-4aa6-aad0-354c6defe117",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlp_tickers = [\n",
    "    \"PG\",    # Procter & Gamble\n",
    "    \"KO\",    # Coca-Cola\n",
    "    \"PEP\",   # PepsiCo\n",
    "    \"COST\",  # Costco Wholesale\n",
    "    \"WMT\",   # Walmart\n",
    "    \"MDLZ\",  # Mondelez International\n",
    "    \"PM\",    # Philip Morris International\n",
    "    \"K\",     # Kellogg\n",
    "    \"CL\",    # Colgate-Palmolive\n",
    "    \"MO\",    # Altria Group\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20e1744a-dbbe-463c-8187-32f4fc46ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "xly_tickers = [\n",
    "    \"AMZN\", # Amazon\n",
    "    \"TSLA\", # Tesla\n",
    "    \"HD\",   # Home Depot\n",
    "    \"MCD\",  # McDonald's\n",
    "    \"NKE\",  # Nike\n",
    "    \"LOW\",  # Lowe's\n",
    "    \"SBUX\", # Starbucks\n",
    "    \"CMG\",  # Chipotle Mexican Grill\n",
    "    \"TJX\",  # TJX Companies\n",
    "    \"BKNG\", # Booking Holdings\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efe20ebd-0cf5-4ecb-8698-9080c05529ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlc_tickers = [\n",
    "    \"GOOGL\", # Alphabet (Google) Class A\n",
    "    \"GOOG\",  # Alphabet (Google) Class C\n",
    "    \"META\",  # Meta Platforms (formerly Facebook)\n",
    "    \"T\",     # AT&T\n",
    "    \"CMCSA\", # Comcast\n",
    "    \"VZ\",    # Verizon\n",
    "    \"TMUS\",  # T-Mobile US\n",
    "    \"NFLX\",  # Netflix\n",
    "    \"CHTR\",  # Charter Communications\n",
    "    \"DIS\",   # Walt Disney\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432cea3c-a6f4-496b-baad-3cae2d587cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a76dd0-56bf-45bd-bca9-e2128a979de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b22b39e-71e7-43ec-8cf9-e9861f0c9503",
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors_list_a = [ \"XLU\", \"XLY\",\"XLP\",\"XLRE\",\"VNQ\",\"KIE\",\"XLF\",\"MOO\",\"XLV\",\"XLI\",\"XLC\",\"XLB\",\"IBB\",\"TAN\",\"KRE\",\"ITB\",\"GDX\",\"XLE\",\"PBW\",\"XLK\",\"XME\",\"SMH\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd9491-9399-49e8-9669-a814e5fe2938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea80040-0059-4aaf-b35e-09eb68a17104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0f5d1c13-39ad-4e6f-a900-c6b0c98bc3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_assets = xlc_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e2db3-def4-439f-ae5f-830de79e8214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
