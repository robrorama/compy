{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "positional encoding"
      ],
      "metadata": {
        "id": "YGBEZNiC-Sim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$PE(p, 2i) = \\sin\\left(\\frac{p}{10000^{2i/d}}\\right), \\quad PE(p, 2i + 1) = \\cos\\left(\\frac{p}{10000^{2i/d}}\\right)$"
      ],
      "metadata": {
        "id": "vGckRTPq9JtM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variational Graph AutoEncoder"
      ],
      "metadata": {
        "id": "QlUonpyB_vBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$H^{(l+1)} = \\sigma\\left(\\tilde{D}^{-1/2}\\tilde{A}\\tilde{D}^{-1/2}H^{(l)}W^{(l)}\\right)$\n"
      ],
      "metadata": {
        "id": "X-24LiWq_orl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "self-attention mechanism\n"
      ],
      "metadata": {
        "id": "2hTSyQjM-Wcm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$\n"
      ],
      "metadata": {
        "id": "GgbwreEM84SD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variational Inference"
      ],
      "metadata": {
        "id": "1V_F2E7a_z9N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\mathcal{L} = \\mathbb{E}_{q(Z|X)}\\left[\\log p(X|Z)\\right] - D_{KL}\\left(q(Z|X) || p(Z)\\right)$\n"
      ],
      "metadata": {
        "id": "42DM__Or_4pM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SU9DeAyW84J4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Noozpq6z8ilj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shannon entropy formula and definition\n",
        "\n",
        "The Shannon entropy $H(X)$ of a random variable $X$ with $n$ possible outcomes $x_1, x_2, \\ldots, x_n$ and probabilities $p_1, p_2, \\ldots, p_n$ is given by:\n",
        "\n",
        "$$H(X) = -\\sum_{i=1}^n p_i \\log_2 p_i$$\n",
        "\n",
        "where $\\log_2$ is the base-2 logarithm.\n",
        "\n",
        "The Shannon entropy measures the average amount of information (in bits) contained in each outcome of the random variable $X$. If all outcomes are equally likely, then the entropy is maximized and equal to $\\log_2 n$.\n",
        "\n",
        "Here's an example of how to calculate the Shannon entropy:\n",
        "\n",
        "Suppose we have a random variable $X$ that takes on values $x_1, x_2, x_3$ with probabilities $p_1 = 0.4, p_2 = 0.3,$ and $p_3 = 0.3$. To calculate the entropy, we use the formula:\n",
        "\n",
        "$$H(X) = -\\sum_{i=1}^3 p_i \\log_2 p_i = -(0.4 \\log_2 0.4 + 0.3 \\log_2 0.3 + 0.3 \\log_2 0.3) \\approx 1.57 \\text{ bits}$$\n",
        "\n",
        "This means that, on average, each outcome of $X$ contains 1.57 bits of information. Note that the entropy is highest when all outcomes are equally likely, and lowest when one outcome has probability 1 and all others have probability 0.\n",
        "\n",
        "In summary, Shannon entropy is a measure of uncertainty or unpredictability in a system, and it can be used to quantify the amount of information contained in a message or data. The formula for Shannon entropy takes into account the probabilities of each possible outcome, and the resulting entropy is measured in bits.\n"
      ],
      "metadata": {
        "id": "DkTQhiAd77Bl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_LheGI291VGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Central Limit Theorem of Calculus\n",
        "\n",
        "The central limit theorem of calculus states that:\n",
        "\n",
        "$$\\lim_{n\\to\\infty}\\sqrt{n}\\left(\\frac{1}{n}\\sum_{i=1}^{n}X_i - \\mu\\right) \\xrightarrow{d} \\mathcal{N}(0, \\sigma^2)$$\n",
        "\n",
        "where $\\{X_i\\}$ is a sequence of independent and identically distributed random variables with mean $\\mu$ and variance $\\sigma^2$. The notation $\\xrightarrow{d}$ indicates convergence in distribution, and $\\mathcal{N}(0, \\sigma^2)$ denotes a normal distribution with mean $0$ and variance $\\sigma^2$.\n"
      ],
      "metadata": {
        "id": "e8DPcxxAappp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating a Derivative\n",
        "\n",
        "To calculate the derivative of a function $f(x)$ at a point $a$, we use the following formula:\n",
        "\n",
        "$$f'(a) = \\lim_{h\\to 0} \\frac{f(a+h) - f(a)}{h}$$\n",
        "\n",
        "where $h$ is a small positive number. Geometrically, the derivative at a point $a$ represents the slope of the tangent line to the function $f(x)$ at that point.\n",
        "\n",
        "The derivative can also be interpreted as the instantaneous rate of change of the function with respect to its input variable.\n",
        "\n",
        "If the derivative exists for all values of $x$ in an interval $I$, we say that the function is differentiable on $I$.\n"
      ],
      "metadata": {
        "id": "QxYW_vEFa1ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Taylor Series Expansion\n",
        "\n",
        "The Taylor series expansion of a function $f(x)$ about a point $a$ is given by:\n",
        "\n",
        "$$f(x) = \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(a)}{n!} (x-a)^n$$\n",
        "\n",
        "where $f^{(n)}(a)$ denotes the $n$th derivative of $f(x)$ evaluated at $a$.\n",
        "\n",
        "The Taylor series provides a way to approximate a function as an infinite sum of simpler functions. The series can be truncated at a certain term to obtain a polynomial approximation of the function.\n",
        "\n",
        "The Taylor series expansion is particularly useful in calculus, where it allows for the computation of derivatives and integrals of functions that are difficult to evaluate directly. It also plays a key role in the development of numerical methods for solving differential equations and in the analysis of numerical algorithms.\n"
      ],
      "metadata": {
        "id": "kwqaLCN3bSh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Taylor Series for Finite Difference Approximations\n",
        "\n",
        "When approximating the derivative of a function using finite difference methods, we can use Taylor series expansions to derive the following approximations:\n",
        "\n",
        "- Forward difference approximation with second order error:\n",
        "\n",
        "  $$f'(x) \\approx \\frac{f(x+h) - f(x)}{h} = f'(x) + \\frac{1}{2} f''(x) h + O(h^2)$$\n",
        "\n",
        "- Backward difference approximation with second order error:\n",
        "\n",
        "  $$f'(x) \\approx \\frac{f(x) - f(x-h)}{h} = f'(x) - \\frac{1}{2} f''(x) h + O(h^2)$$\n",
        "\n",
        "where $h$ is the step size of the approximation and $O(h^2)$ denotes the second order error term, which represents the difference between the true value of the derivative and the approximation.\n",
        "\n",
        "The forward and backward difference approximations can be used to compute the derivative of a function at a point, provided that the function is differentiable and continuous in the neighborhood of the point.\n",
        "\n",
        "In practice, the choice of step size $h$ is a tradeoff between accuracy and computational cost, as smaller step sizes generally lead to more accurate approximations but require more function evaluations.\n",
        "\n",
        "Note that these approximations assume that the second derivative of the function is continuous and bounded, and that the step size $h$ is sufficiently small. In general, higher order approximations can be obtained by including additional terms in the Taylor series expansion.\n"
      ],
      "metadata": {
        "id": "xbaBlHHrcIAx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Taylor Series for Finite Difference Approximations (Including Third Order Error)\n",
        "\n",
        "In addition to the second order error terms, the Taylor series expansions for finite difference approximations can also include third order error terms:\n",
        "\n",
        "- Forward difference approximation with third order error:\n",
        "\n",
        "  $$f'(x) \\approx \\frac{-3f(x) + 4f(x+h) - f(x+2h)}{2h} = f'(x) + \\frac{1}{3} f'''(x) h^2 + O(h^3)$$\n",
        "\n",
        "- Backward difference approximation with third order error:\n",
        "\n",
        "  $$f'(x) \\approx \\frac{3f(x) - 4f(x-h) + f(x-2h)}{2h} = f'(x) - \\frac{1}{3} f'''(x) h^2 + O(h^3)$$\n",
        "\n",
        "where $h$ is the step size of the approximation, $O(h^2)$ denotes the second order error term, and $O(h^3)$ denotes the third order error term.\n",
        "\n",
        "The third order error term represents the difference between the true value of the derivative and the approximation, and is proportional to $h^2$. As a result, the third order approximation is generally more accurate than the second order approximation for small values of $h$.\n",
        "\n",
        "The forward and backward difference approximations can be used to compute the derivative of a function at a point, provided that the function is differentiable and continuous in the neighborhood of the point.\n",
        "\n",
        "In practice, the choice of step size $h$ is a tradeoff between accuracy and computational cost, as smaller step sizes generally lead to more accurate approximations but require more function evaluations.\n",
        "\n",
        "Note that these approximations assume that the third derivative of the function is continuous and bounded, and that the step size $h$ is sufficiently small. In general, higher order approximations can be obtained by including additional terms in the Taylor series expansion.\n"
      ],
      "metadata": {
        "id": "Nk1rgufqc_Rt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Factorials\n",
        "- $1!=1$\n",
        "- $2!=2\\cdot 1=2$\n",
        "- $3!=3\\cdot 2\\cdot 1=6$\n",
        "- $4!=4\\cdot 3\\cdot 2\\cdot 1=24$\n",
        "- $5!=5\\cdot 4\\cdot 3\\cdot 2\\cdot 1=120$\n"
      ],
      "metadata": {
        "id": "DCeCsWefhOst"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Symbol | Definition\n",
        "------- | --------\n",
        "$\\lim$ | The limit of a function as $x$ approaches a certain value\n",
        "$\\Delta x$ | The change in $x$\n",
        "$\\Delta y$ | The change in $y$\n",
        "$f(x)$ | The value of the function $f$ at the point $x$\n",
        "$f'(x)$ | The derivative of $f$ at the point $x$\n",
        "$f''(x)$ | The second derivative of $f$ at the point $x$\n",
        "$f'''(x)$ | The third derivative of $f$ at the point $x$\n",
        "$\\int_a^b f(x) dx$ | The definite integral of $f$ from $a$ to $b$\n",
        "$\\int f(x) dx$ | The indefinite integral of $f$\n",
        "$\\frac{dx}{dx}$ | The symbol for the derivative with respect to $x$\n",
        "$\\frac{dy}{dx}$ | The symbol for the derivative of $y$ with respect to $x$\n",
        "$\\frac{d^2y}{dx^2}$ | The symbol for the second derivative of $y$ with respect to $x$\n",
        "$\\frac{d^3y}{dx^3}$ | The symbol for the third derivative of $y$ with respect to $x$\n",
        "$\\nabla$ | The gradient operator\n",
        "$\\nabla f$ | The gradient of the function $f$\n",
        "$\\nabla^2 f$ | The Laplacian of the function $f$\n"
      ],
      "metadata": {
        "id": "-uM7jz4KHMMN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tOjOaJg_anAz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbols of Linear Algebra\n",
        "\n",
        "Here are some common symbols used in linear algebra:\n",
        "\n",
        "Symbol | Definition\n",
        "------- | --------\n",
        "$\\mathbf{A}$ | A matrix\n",
        "$\\mathbf{B}$ | Another matrix\n",
        "$\\mathbf{x}$ | A column vector\n",
        "$\\mathbf{y}$ | Another column vector\n",
        "$\\mathbf{z}$ | Yet another column vector\n",
        "$\\mathbf{0}$ | The zero vector\n",
        "$\\mathbf{1}$ | The vector of all ones\n",
        "$\\mathbf{e}_i$ | The standard basis vector of length $n$ in the $i$th direction\n",
        "$\\mathbf{A}^\\top$ | The transpose of $\\mathbf{A}$\n",
        "$\\mathrm{Tr}(\\mathbf{A})$ | The trace of $\\mathbf{A}$\n",
        "$\\det(\\mathbf{A})$ | The determinant of $\\mathbf{A}$\n",
        "$\\mathbf{A}^{-1}$ | The inverse of $\\mathbf{A}$\n",
        "$\\lambda_1, \\lambda_2, \\ldots, \\lambda_n$ | The eigenvalues of $\\mathbf{A}$\n",
        "$\\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_n$ | The eigenvectors of $\\mathbf{A}$\n",
        "$\\langle \\mathbf{v}, \\mathbf{w} \\rangle$ | The inner product of $\\mathbf{v}$ and $\\mathbf{w}$\n",
        "$\\|\\mathbf{v}\\|$ | The norm (length) of $\\mathbf{v}$\n",
        "$\\mathbf{v} \\perp \\mathbf{w}$ | $\\mathbf{v}$ is orthogonal to $\\mathbf{w}$\n",
        "$\\mathrm{proj}_{\\mathbf{v}}(\\mathbf{w})$ | The projection of $\\mathbf{w}$ onto $\\mathbf{v}$\n",
        "$\\mathrm{GS}(\\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_n)$ | The Gram-Schmidt process of $\\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_n$\n"
      ],
      "metadata": {
        "id": "zwxmK7SAZjTl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbols of Linear Algebra\n",
        "\n",
        "Here are some common and less common symbols used in linear algebra:\n",
        "\n",
        "Symbol | Definition\n",
        "-------| --------\n",
        "$\\mathbf{A}$ | A matrix\n",
        "$\\mathbf{B}$ | Another matrix\n",
        "$\\mathbf{x}$ | A column vector\n",
        "$\\mathbf{y}$ | Another column vector\n",
        "$\\mathbf{z}$ | Yet another column vector\n",
        "$\\mathbf{0}$ | The zero vector\n",
        "$\\mathbf{1}$ | The vector of all ones\n",
        "$\\mathbf{e}_i$ | The standard basis vector of length $n$ in the $i$th direction\n",
        "$\\mathbf{A}^\\top$ | The transpose of $\\mathbf{A}$\n",
        "$\\mathrm{Tr}(\\mathbf{A})$ | The trace of $\\mathbf{A}$\n",
        "$\\det(\\mathbf{A})$ | The determinant of $\\mathbf{A}$\n",
        "$\\mathbf{A}^{-1}$ | The inverse of $\\mathbf{A}$\n",
        "$\\lambda_1, \\lambda_2, \\ldots, \\lambda_n$ | The eigenvalues of $\\mathbf{A}$\n",
        "$\\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_n$ | The eigenvectors of $\\mathbf{A}$\n",
        "$\\langle \\mathbf{v}, \\mathbf{w} \\rangle$ | The inner product of $\\mathbf{v}$ and $\\mathbf{w}$\n",
        "$\\|\\mathbf{v}\\|$ | The norm (length) of $\\mathbf{v}$\n",
        "$\\mathbf{v} \\perp \\mathbf{w}$ | $\\mathbf{v}$ is orthogonal to $\\mathbf{w}$\n",
        "$\\mathrm{proj}_{\\mathbf{v}}(\\mathbf{w})$ | The projection of $\\mathbf{w}$ onto $\\mathbf{v}$\n",
        "$\\mathrm{GS}(\\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_n)$ | The Gram-Schmidt process of $\\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_n$\n",
        "$\\mathbf{A}^\\dagger$ | The pseudoinverse of $\\mathbf{A}$\n",
        "$\\mathbf{A}^\\#$ | The Moore-Penrose inverse of $\\mathbf{A}$\n",
        "$\\mathbf{A}^*$ | The conjugate transpose (Hermitian transpose) of $\\mathbf{A}$\n",
        "$\\mathbf{A}^{(k)}$ | The $k$th matrix power of $\\mathbf{A}$, i.e., $\\mathbf{A}$ multiplied by itself $k$ times\n",
        "$\\mathbf{I}$ | The identity matrix\n",
        "$\\mathbf{J}$ | The matrix of all ones\n",
        "$\\mathbf{D}$ | A diagonal matrix\n",
        "$\\mathbf{L}$ | A lower triangular matrix\n",
        "$\\mathbf{U}$ | An upper triangular matrix\n",
        "$\\mathbf{P}$ | A permutation matrix\n",
        "$\\mathbf{Q}$ | An orthogonal matrix\n",
        "$\\mathbf{R}$ | A rotation matrix\n",
        "$\\mathbf{S}$ | A skew-symmetric matrix\n",
        "$\\mathbf{H}$ | A Hermitian matrix\n",
        "$\\mathbf{G}$ | A positive-definite matrix\n",
        "$\\mathbf{K}$ | A positive semi-definite matrix\n",
        "$\\mathbf{T\n"
      ],
      "metadata": {
        "id": "CmTLXST3bJPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbols of Pre-Algebra, Algebra I and II, and College Algebra\n",
        "\n",
        "Here are some common symbols used in pre-algebra, algebra I and II, and college algebra:\n",
        "\n",
        "Symbol | Definition\n",
        "-------| --------\n",
        "$x$ | A variable representing a number\n",
        "$a$, $b$, $c$ | Constants representing numbers\n",
        "$+$ | Addition\n",
        "$-$ | Subtraction\n",
        "$\\times$ | Multiplication\n",
        "$\\div$ | Division\n",
        "$=$ | Equality\n",
        "$\\neq$ | Inequality (not equal to)\n",
        "$\\lt$ | Less than\n",
        "$\\gt$ | Greater than\n",
        "$\\leq$ | Less than or equal to\n",
        "$\\geq$ | Greater than or equal to\n",
        "$()$ | Parentheses (used to group operations)\n",
        "$|$ | Divides (e.g., $a \\mid b$ means $a$ divides $b$)\n",
        "$\\sqrt{x}$ | The square root of $x$\n",
        "$x^2$ | The square of $x$\n",
        "$x^n$ | The $n$th power of $x$\n",
        "$2x$, $3x$, $\\ldots$ | Coefficients of $x$\n",
        "$a_n$, $a_{n-1}$, $\\ldots$, $a_1$ | Coefficients of a polynomial in descending order of degree\n",
        "$\\sum_{i=1}^n a_i$ | The sum of the terms $a_1$, $a_2$, $\\ldots$, $a_n$\n",
        "$\\prod_{i=1}^n a_i$ | The product of the terms $a_1$, $a_2$, $\\ldots$, $a_n$\n",
        "$f(x)$ | A function of $x$\n",
        "$\\frac{dy}{dx}$ | The derivative of $y$ with respect to $x$\n",
        "$\\frac{d^2y}{dx^2}$ | The second derivative of $y$ with respect to $x$\n",
        "$\\log_b x$ | The logarithm of $x$ with base $b$\n",
        "$\\ln x$ | The natural logarithm of $x$\n",
        "$e$ | Euler's number (approximately 2.71828)\n",
        "$!$ | Factorial (e.g., $5!$ means 5 factorial, or $5 \\times 4 \\times 3 \\times 2 \\times 1$)\n",
        "$\\binom{n}{k}$ | The binomial coefficient, or the number of ways to choose $k$ items from a set of $n$ items (read as \"n choose k\")\n",
        "$\\infty$ | Infinity\n",
        "$\\mathbb{N}$ | The set of natural numbers (positive integers)\n",
        "$\\mathbb{Z}$ | The set of integers (positive and negative)\n",
        "$\\mathbb{Q}$ | The set of rational numbers (fractions)\n",
        "$\\mathbb{R}$ | The set of real numbers (numbers that can be represented on a number line)\n",
        "$\\mathbb{C}$ | The set of complex numbers (numbers of the form $a + bi$, where $a$ and $b$ are real numbers and $i$ is the imaginary unit, defined as $\\sqrt{-1}$)\n"
      ],
      "metadata": {
        "id": "KnW_hJ8xbxWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbols of Trigonometry, Geometry, Pre-Calculus, and Calculus 1\n",
        "\n",
        "Here are some common symbols used in trigonometry, geometry, pre-calculus, and calculus 1:\n",
        "\n",
        "Symbol | Definition\n",
        "-------| --------\n",
        "$\\theta$ | An angle\n",
        "$r$ | The radius or distance from the origin to a point in polar coordinates\n",
        "$(x,y)$ | A point in Cartesian coordinates\n",
        "$(r,\\theta)$ | A point in polar coordinates\n",
        "$\\sin \\theta$ | The sine of $\\theta$\n",
        "$\\cos \\theta$ | The cosine of $\\theta$\n",
        "$\\tan \\theta$ | The tangent of $\\theta$\n",
        "$\\csc \\theta$ | The cosecant of $\\theta$ (the reciprocal of the sine)\n",
        "$\\sec \\theta$ | The secant of $\\theta$ (the reciprocal of the cosine)\n",
        "$\\cot \\theta$ | The cotangent of $\\theta$ (the reciprocal of the tangent)\n",
        "$\\arcsin x$ | The inverse sine of $x$ (the angle whose sine is $x$)\n",
        "$\\arccos x$ | The inverse cosine of $x$ (the angle whose cosine is $x$)\n",
        "$\\arctan x$ | The inverse tangent of $x$ (the angle whose tangent is $x$)\n",
        "$\\triangle ABC$ | A triangle with vertices $A$, $B$, and $C$\n",
        "$a$, $b$, $c$ | The side lengths of a triangle\n",
        "$h$ | The height of a triangle\n",
        "$r$ | The radius of a circle\n",
        "$A$ | The area of a shape\n",
        "$P$ | The perimeter or circumference of a shape\n",
        "$V$ | The volume of a shape\n",
        "$\\lim_{x \\to a} f(x)$ | The limit of $f(x)$ as $x$ approaches $a$\n",
        "$f'(x)$ | The derivative of $f(x)$ with respect to $x$\n",
        "$f''(x)$ | The second derivative of $f(x)$ with respect to $x$\n",
        "$\\int f(x) dx$ | The indefinite integral of $f(x)$\n",
        "$\\int_a^b f(x) dx$ | The definite integral of $f(x)$ from $a$ to $b$\n",
        "$\\frac{d}{dx}$ | The operator for taking the derivative with respect to $x$\n",
        "$\\frac{d^n y}{dx^n}$ | The $n$th derivative of $y$ with respect to $x$\n",
        "$\\Sigma$ | The summation symbol (e.g., $\\sum_{k=1}^n k$ means the sum of the integers from 1 to $n$)\n",
        "$\\prod$ | The product symbol (e.g., $\\prod_{i=1}^n a_i$ means the product of the numbers $a_1, a_2, \\ldots, a_n$)\n",
        "$\\log_b x$ | The logarithm of $x$ with base $b$\n",
        "$e$ | Euler's number (approximately 2.71828)\n",
        "$\\infty$ | Infinity\n",
        "$\\mathbb{N}$ | The set of natural numbers (positive integers)\n",
        "$\\mathbb{Z}$ | The set of integers (positive and negative)\n",
        "$\\mathbb{Q}$ | The set of rational numbers (fractions)\n",
        "$\\mathbb{R}$ | The set of real numbers (numbers that can be represented on a number line)\n",
        "$\\mathbb{C}$ | The set of complex numbers (numbers of the form $a + bi$, where $a$ and $b$ are real numbers and $i\n"
      ],
      "metadata": {
        "id": "kT3n0MuecNab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbols of Calculus 2 and Calculus 3\n",
        "\n",
        "Here are some common symbols used in Calculus 2 and Calculus 3:\n",
        "\n",
        "Symbol | Definition\n",
        "-------| --------\n",
        "$u$, $v$, $w$ | Functions of $x$\n",
        "$du$, $dv$, $dw$ | Infinitesimal changes in $u$, $v$, $w$\n",
        "$y=f(u)$ | A function of $u$\n",
        "$\\frac{dy}{du}$ | The derivative of $y$ with respect to $u$\n",
        "$\\frac{dy}{dx}$ | The derivative of $y$ with respect to $x$\n",
        "$\\frac{du}{dx}$ | The derivative of $u$ with respect to $x$\n",
        "$\\frac{d}{dx} \\left[f(u)\\right]$ | The chain rule for derivatives\n",
        "$\\int u \\, dv$ | Integration by parts\n",
        "$\\int_a^b f(x) \\, dx$ | The definite integral of $f(x)$ from $a$ to $b$\n",
        "$\\int_{-\\infty}^\\infty f(x) \\, dx$ | The improper integral of $f(x)$ over the entire real line\n",
        "$\\int f(u(x)) \\, u'(x) \\, dx$ | The substitution rule for integrals\n",
        "$\\int_0^{2\\pi} f(\\theta) \\, d\\theta$ | The definite integral of $f(\\theta)$ over the interval $[0,2\\pi]$\n",
        "$\\iint_R f(x,y) \\, dA$ | The double integral of $f(x,y)$ over the region $R$ in the $xy$-plane\n",
        "$\\iiint_E f(x,y,z) \\, dV$ | The triple integral of $f(x,y,z)$ over the solid region $E$ in three-dimensional space\n",
        "$\\frac{\\partial f}{\\partial x}$ | The partial derivative of $f(x,y)$ with respect to $x$\n",
        "$\\frac{\\partial^2 f}{\\partial x^2}$ | The second partial derivative of $f(x,y)$ with respect to $x$\n",
        "$\\nabla$ | The gradient operator\n",
        "$\\nabla f$ | The gradient of the function $f(x,y)$ or $f(x,y,z)$\n",
        "$\\nabla \\cdot \\mathbf{F}$ | The divergence of the vector field $\\mathbf{F}$\n",
        "$\\nabla \\times \\mathbf{F}$ | The curl of the vector field $\\mathbf{F}$\n",
        "$\\iint_S \\mathbf{F} \\cdot d\\mathbf{S}$ | The flux of the vector field $\\mathbf{F}$ across the surface $S$\n",
        "$\\iint_R f(x,y) \\, dA$ | The double integral of $f(x,y)$ over the region $R$ in the $xy$-plane\n",
        "$\\iiint_E f(x,y,z) \\, dV$ | The triple integral of $f(x,y,z)$ over the solid region $E$ in three-dimensional space\n",
        "$\\iint_S \\mathbf{F} \\cdot d\\mathbf{S}$ | The flux of the vector field $\\mathbf{F}$ across the surface $S$\n",
        "$\\oint_C \\mathbf{F} \\cdot d\\mathbf{r}$ | The line integral of the vector field $\\mathbf{F}$ along the curve $C$\n",
        "$\\oint_C f(x,y) \\, ds$ | The line integral of the scalar function $f(x,y)$ along the curve\n"
      ],
      "metadata": {
        "id": "8K0tYE9Dc38W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transcendental Numbers\n",
        "\n",
        "Here are some common transcendental numbers:\n",
        "\n",
        "Number | Definition\n",
        "-------| --------\n",
        "$\\pi$ | The ratio of the circumference of a circle to its diameter\n",
        "$e$ | The base of the natural logarithm\n",
        "$\\phi$ | The golden ratio, equal to $\\frac{1 + \\sqrt{5}}{2}$\n",
        "$\\gamma$ | The Euler-Mascheroni constant, approximately equal to $0.5772156649$\n",
        "$2^{1/2}$ | The square root of 2\n",
        "$3^{1/2}$ | The square root of 3\n",
        "$\\ln 2$ | The natural logarithm of 2\n",
        "$\\ln 10$ | The natural logarithm of 10\n",
        "$e^\\pi$ | Euler's number raised to the power of $\\pi$\n",
        "$\\pi^e$ | $\\pi$ raised to the power of $e$\n",
        "$e^\\gamma$ | Euler's number raised to the power of $\\gamma$\n",
        "$\\pi^\\gamma$ | $\\pi$ raised to the power of $\\gamma$\n",
        "$\\mathrm{Li}_2(\\frac{1}{2})$ | The dilogarithm function evaluated at $\\frac{1}{2}$\n",
        "$\\mathrm{G}(1)$ | Catalan's constant, equal to $\\sum_{n=0}^\\infty \\frac{(-1)^n}{(2n+1)^2} \\approx 0.91596559417$\n",
        "$\\zeta(3)$ | The Apéry's constant, equal to $\\sum_{n=1}^\\infty \\frac{1}{n^3} \\approx 1.20205690316$\n"
      ],
      "metadata": {
        "id": "jPl-a_vWeNWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transcendental Numbers\n",
        "\n",
        "Here are some more common transcendental numbers:\n",
        "\n",
        "Number | Definition\n",
        "-------| --------\n",
        "$2^e$ | $2$ raised to the power of $e$\n",
        "$3^e$ | $3$ raised to the power of $e$\n",
        "$\\pi^2$ | $\\pi$ squared\n",
        "$\\pi^3$ | $\\pi$ cubed\n",
        "$e^{\\pi/2}$ | Euler's number raised to the power of $\\frac{\\pi}{2}$\n",
        "$e^{\\sqrt{2}}$ | Euler's number raised to the power of $\\sqrt{2}$\n",
        "$e^\\phi$ | Euler's number raised to the power of the golden ratio\n",
        "$\\pi^\\phi$ | $\\pi$ raised to the power of the golden ratio\n",
        "$\\ln(\\phi)$ | The natural logarithm of the golden ratio\n",
        "$\\ln(\\pi)$ | The natural logarithm of $\\pi$\n",
        "$\\sqrt{\\pi}$ | The square root of $\\pi$\n",
        "$\\sqrt{e}$ | The square root of Euler's number\n",
        "$e^{e}$ | Euler's number raised to the power of itself\n",
        "$\\pi^e$ | $\\pi$ raised to the power of $e$\n",
        "$e^\\gamma$ | Euler's number raised to the power of the Euler-Mascheroni constant\n",
        "$\\pi^\\gamma$ | $\\pi$ raised to the power of the Euler-Mascheroni constant\n",
        "$2\\pi$ | Twice the value of $\\pi$\n",
        "$\\frac{\\pi}{2}$ | Half the value of $\\pi$\n",
        "$\\frac{\\pi}{4}$ | One quarter of the value of $\\pi$\n",
        "$\\sqrt{2\\pi}$ | The square root of two times the value of $\\pi$\n",
        "$\\pi^{-1}$ | The reciprocal of $\\pi$\n",
        "$e^{-1}$ | The reciprocal of Euler's number\n",
        "$\\sqrt{2\\pi e}$ | The square root of two times the value of $\\pi$ times Euler's number\n",
        "$\\ln(\\sqrt{2\\pi e})$ | The natural logarithm of the square root of two times the value of $\\pi$ times Euler's number\n",
        "$\\zeta(2)$ | The Riemann zeta function evaluated at $2$, equal to $\\sum_{n=1}^\\infty \\frac{1}{n^2} = \\frac{\\pi^2}{6}$\n",
        "$\\zeta(4)$ | The Riemann zeta function evaluated at $4$, equal to $\\sum_{n=1}^\\infty \\frac{1}{n^4}$\n",
        "$\\zeta(5)$ | The Riemann zeta function evaluated at $5$, equal to $\\sum_{n=1}^\\infty \\frac{1}{n^5}$\n",
        "$\\zeta(6)$ | The Riemann zeta function evaluated at $6$, equal to $\\sum_{n=1}^\\infty \\frac{1}{n^6}$\n",
        "$\\zeta(7)$ | The Riemann zeta function evaluated at $7$, equal to $\\sum_{n=1}^\\infty \\frac{1}{n^7}$\n",
        "$\\zeta(8)$ | The Riemann zeta function evaluated at $8$, equal to $\\sum_{n=1}^\\infty \\frac{1}{n^8}$\n",
        "$\\zeta(9)$ | The Riemann zeta function evaluated at $9$, equal to $\\sum_{n=1}^\\infty \\frac{1}{n^9}\n"
      ],
      "metadata": {
        "id": "-6xRJRLAevQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abstract Algebra\n",
        "- **Group theory**: $(G,\\cdot)$\n",
        "- **Ring theory**: $(R,+,\\cdot)$\n",
        "\n",
        "## Analysis\n",
        "- **Real analysis**: $\\lim_{x\\to a}f(x)$, $f'(x)$, $\\int_a^b f(x) dx$\n",
        "- **Complex analysis**: $f(z)$, $\\oint_C f(z) dz$, $\\text{Res}(f,z)$\n",
        "- **Functional analysis**: $\\langle x,y\\rangle$, $\\|x\\|$, $T:X\\to Y$\n",
        "- **Fourier analysis**: $\\hat{f}(\\xi)$, $\\mathcal{F}(f)$\n",
        "\n",
        "## Combinatorics\n",
        "- **Graph theory**: $G=(V,E)$, $\\text{deg}(v)$, $\\chi(G)$\n",
        "- **Combinatorial optimization**: $\\text{max}\\{c^Tx : Ax \\leq b\\}$, $TSP$\n",
        "- **Combinatorial designs**: $t$-design, $q$-ary code\n",
        "\n",
        "## Geometry\n",
        "- **Differential geometry**: $\\gamma(t)$, $T(\\gamma)$, $K(p)$\n",
        "- **Topology**: $X$, $U$, $\\text{int}(U)$\n",
        "- **Algebraic geometry**: $f(x,y)$, $V(f)$, $\\text{deg}(f)$\n",
        "\n",
        "## Number Theory\n",
        "- **Analytic number theory**: $\\zeta(s)$, $\\psi(x)$, $E(x)$\n",
        "- **Algebraic number theory**: $\\mathcal{O}_K$, $Cl(K)$, $h_K$\n",
        "- **Diophantine equations**: $ax+by=c$, $x^2+y^2=z^2$, $E:y^2=x^3+ax+b$\n"
      ],
      "metadata": {
        "id": "SeYBUun7q8na"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbols of Graph Theory\n",
        "\n",
        "Here are some common symbols used in graph theory:\n",
        "\n",
        "Symbol | Definition\n",
        "-------| --------\n",
        "$G$ | A graph\n",
        "$V(G)$ | The set of vertices of the graph $G$\n",
        "$E(G)$ | The set of edges of the graph $G$\n",
        "$(u,v)$ | An edge of the graph $G$ connecting vertices $u$ and $v$\n",
        "$K_n$ | The complete graph on $n$ vertices\n",
        "$C_n$ | The cycle graph on $n$ vertices\n",
        "$P_n$ | The path graph on $n$ vertices\n",
        "$G \\cup H$ | The union of graphs $G$ and $H$\n",
        "$G \\cap H$ | The intersection of graphs $G$ and $H$\n",
        "$G \\setminus H$ | The difference of graphs $G$ and $H$\n",
        "$G + H$ | The disjoint union of graphs $G$ and $H$\n",
        "$\\Delta(G)$ | The maximum degree of any vertex in the graph $G$\n",
        "$\\delta(G)$ | The minimum degree of any vertex in the graph $G$\n",
        "$N_G(v)$ | The neighborhood of the vertex $v$ in the graph $G$\n",
        "$K_{m,n}$ | The complete bipartite graph with $m$ vertices in one partition and $n$ vertices in the other partition\n",
        "$K_n - e$ | The graph obtained by deleting an edge $e$ from the complete graph $K_n$\n",
        "$K_n - v$ | The graph obtained by deleting a vertex $v$ from the complete graph $K_n$\n",
        "$P_n * P_m$ | The cartesian product of the path graph $P_n$ and the path graph $P_m$\n",
        "$G \\times H$ | The cartesian product of graphs $G$ and $H$\n",
        "$G \\to H$ | The existence of a homomorphism from graph $G$ to graph $H$\n",
        "$G \\leftrightarrow H$ | The existence of an isomorphism between graphs $G$ and $H$\n",
        "$G^{(k)}$ | The $k$-th power of graph $G$, obtained by adding edges between vertices whose shortest path has length at most $k$\n",
        "$\\chi(G)$ | The chromatic number of graph $G$, the minimum number of colors needed to color the vertices of $G$ so that no two adjacent vertices have the same color\n",
        "$\\omega(G)$ | The clique number of graph $G$, the maximum number of pairwise adjacent vertices in $G$\n",
        "$\\tau(G)$ | The independence number of graph $G$, the maximum number of pairwise non-adjacent vertices in $G$\n",
        "$\\chi'(G)$ | The chromatic index of graph $G$, the minimum number of colors needed to color the edges of $G$ so that no two adjacent edges have the same color\n",
        "$\\lambda(G)$ | The edge covering number of graph $G$, the minimum number of edges needed to cover all the vertices of $G$\n",
        "$\\overline{G}$ | The complement of graph $G$, the graph with the same vertex set as $G$ but with an edge between any two vertices that are not adjacent in $G$\n"
      ],
      "metadata": {
        "id": "9DRNfZOdrfPm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbols of Graph Theory\n",
        "\n",
        "Here are some more symbols used in graph theory:\n",
        "\n",
        "Symbol | Definition\n",
        "-------| --------\n",
        "$G'$ | The complement of the graph $G$\n",
        "$G[X]$ | The subgraph of $G$ induced by the vertex set $X$\n",
        "$G - v$ | The subgraph of $G$ obtained by removing vertex $v$ and all edges incident to $v$\n",
        "$G - e$ | The subgraph of $G$ obtained by removing edge $e$\n",
        "$G \\setminus e$ | The subgraph of $G$ obtained by removing edge $e$\n",
        "$G + e$ | The graph obtained by adding edge $e$ to graph $G$\n",
        "$G + v$ | The graph obtained by adding vertex $v$ to graph $G$\n",
        "$\\overline{K_n}$ | The null graph, a graph with $n$ vertices and no edges\n",
        "$\\overline{G - e}$ | The graph obtained by adding an edge complementary to $e$ to the graph $G - e$\n",
        "$G \\cup H$ | The union of graphs $G$ and $H$\n",
        "$G \\cap H$ | The intersection of graphs $G$ and $H$\n",
        "$G \\Delta H$ | The symmetric difference of graphs $G$ and $H$\n",
        "$G \\lor H$ | The join of graphs $G$ and $H$\n",
        "$G \\land H$ | The intersection of graphs $G$ and $H$ viewed as subgraphs of the complete graph on the same vertex set\n",
        "$G \\times H$ | The cartesian product of graphs $G$ and $H$\n",
        "$\\chi(G)$ | The chromatic number of graph $G$, the minimum number of colors needed to color the vertices of $G$ so that no two adjacent vertices have the same color\n",
        "$\\chi'(G)$ | The chromatic index of graph $G$, the minimum number of colors needed to color the edges of $G$ so that no two adjacent edges have the same color\n",
        "$\\omega(G)$ | The clique number of graph $G$, the maximum number of pairwise adjacent vertices in $G$\n",
        "$\\alpha(G)$ | The independence number of graph $G$, the maximum number of pairwise non-adjacent vertices in $G$\n",
        "$\\beta(G)$ | The vertex covering number of graph $G$, the minimum number of vertices needed to cover all the edges of $G$\n",
        "$\\gamma(G)$ | The domination number of graph $G$, the minimum number of vertices needed to dominate all the vertices of $G$\n",
        "$\\lambda(G)$ | The edge covering number of graph $G$, the minimum number of edges needed to cover all the vertices of $G$\n",
        "$\\tau(G)$ | The matching number of graph $G$, the maximum number of pairwise non-adjacent edges in $G$\n",
        "$N_G(v)$ | The neighborhood of the vertex $v$ in the graph $G$\n",
        "$d_G(v)$ | The degree of the vertex $v$ in the graph $G$\n",
        "$\\Delta(G)$ | The maximum degree of any vertex in the graph $G$\n",
        "$\\delta(G)$ | The minimum degree of any vertex in the graph $G$\n",
        "$\\kappa(G)$ | The vertex connectivity of graph $G$, the minimum number of vertices that need to be removed to disconnect $G$\n",
        "$\\kappa'(G)$ | The edge connectivity of graph $G$, the minimum number of edges that need to be removed to disconnect $G$\n",
        "$G \\to H$ | The existence of a homomorphism from graph $G$ to graph $H$\n",
        "$G \\\n"
      ],
      "metadata": {
        "id": "3RlHjH8YrjDa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbols of Machine Learning\n",
        "\n",
        "Here are some common symbols used in machine learning:\n",
        "\n",
        "Symbol | Definition\n",
        "-------| --------\n",
        "$\\mathbf{x}$ | An input feature vector\n",
        "$\\mathbf{y}$ | A target vector\n",
        "$\\mathbf{w}$ | A weight vector\n",
        "$\\mathbf{b}$ | A bias vector\n",
        "$\\hat{\\mathbf{y}}$ | A predicted output vector\n",
        "$y_i$ | The $i$-th component of the target vector\n",
        "$\\hat{y}_i$ | The $i$-th component of the predicted output vector\n",
        "$x_{ij}$ | The $j$-th feature of the $i$-th input\n",
        "$w_j$ | The $j$-th component of the weight vector\n",
        "$b$ | The bias term\n",
        "$X$ | The matrix of input features\n",
        "$Y$ | The matrix of target values\n",
        "$\\mathcal{D}$ | The dataset, consisting of pairs of input vectors and their corresponding target vectors\n",
        "$L(\\theta)$ | The loss function, which measures the difference between the predicted output and the actual output for a given set of parameters $\\theta$\n",
        "$\\theta$ | The parameters of a machine learning model\n",
        "$H(\\cdot)$ | A hypothesis function or model, which takes input features and outputs predictions\n",
        "$f(\\cdot)$ | An activation function\n",
        "$z_i$ | The output of a neuron before applying the activation function\n",
        "$g(\\cdot)$ | A function used for regularization, such as L1 or L2 regularization\n",
        "$\\nabla_\\theta L(\\theta)$ | The gradient of the loss function with respect to the model parameters\n",
        "$\\alpha$ | The learning rate, a hyperparameter that controls the step size of gradient descent\n",
        "$\\eta$ | The momentum coefficient, a hyperparameter that controls the amount of influence previous gradient steps have on the current step\n",
        "$\\epsilon$ | A small constant used to avoid division by zero in some calculations\n",
        "$\\mathcal{N}(\\mu,\\,\\sigma^{2})$ | A normal distribution with mean $\\mu$ and variance $\\sigma^2$\n",
        "$\\mathcal{U}(a,b)$ | A uniform distribution between $a$ and $b$\n",
        "$\\mathcal{B}(p)$ | A Bernoulli distribution with probability $p$ of success\n",
        "$\\mathcal{L}(y_i, \\hat{y}_i)$ | The loss function for a single data point, which measures the difference between the predicted output and the actual output\n",
        "$\\mathcal{L}(\\mathbf{y}, \\hat{\\mathbf{y}})$ | The loss function for the entire dataset, which is the sum of the losses for each individual data point\n",
        "$\\mathbf{W}$ | The weight matrix\n",
        "$\\mathbf{X}$ | The matrix of input features\n",
        "$\\mathbf{Y}$ | The matrix of target values\n",
        "$\\mathbf{Z}$ | The matrix of outputs before applying the activation function\n"
      ],
      "metadata": {
        "id": "peSWkPPbr7Hd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbols of Deep Learning\n",
        "\n",
        "Here are some common symbols used in deep learning:\n",
        "\n",
        "Symbol | Definition\n",
        "-------| --------\n",
        "$\\mathbf{x}$ | An input feature vector\n",
        "$\\mathbf{y}$ | A target vector\n",
        "$\\mathbf{w}$ | A weight vector\n",
        "$\\mathbf{b}$ | A bias vector\n",
        "$\\mathbf{z}$ | A hidden layer vector\n",
        "$\\mathbf{a}$ | An activation vector\n",
        "$\\mathbf{h}$ | A hidden state vector\n",
        "$\\hat{\\mathbf{y}}$ | A predicted output vector\n",
        "$y_i$ | The $i$-th component of the target vector\n",
        "$\\hat{y}_i$ | The $i$-th component of the predicted output vector\n",
        "$x_{ij}$ | The $j$-th feature of the $i$-th input\n",
        "$w_{ij}$ | The weight from the $j$-th neuron in the $(l-1)$-th layer to the $i$-th neuron in the $l$-th layer\n",
        "$b_i$ | The bias term for the $i$-th neuron in a layer\n",
        "$z_i$ | The input to the activation function for the $i$-th neuron in a layer\n",
        "$a_i$ | The output of the activation function for the $i$-th neuron in a layer\n",
        "$h_t$ | The hidden state of a recurrent neural network at time $t$\n",
        "$X$ | The matrix of input features\n",
        "$Y$ | The matrix of target values\n",
        "$\\mathcal{D}$ | The dataset, consisting of pairs of input vectors and their corresponding target vectors\n",
        "$L(\\theta)$ | The loss function, which measures the difference between the predicted output and the actual output for a given set of parameters $\\theta$\n",
        "$\\theta$ | The parameters of a deep learning model\n",
        "$H(\\cdot)$ | A deep learning model, which takes input features and outputs predictions\n",
        "$f(\\cdot)$ | An activation function used in deep learning, such as ReLU or sigmoid\n",
        "$\\nabla_\\theta L(\\theta)$ | The gradient of the loss function with respect to the model parameters\n",
        "$\\alpha$ | The learning rate, a hyperparameter that controls the step size of gradient descent\n",
        "$\\eta$ | The momentum coefficient, a hyperparameter that controls the amount of influence previous gradient steps have on the current step\n",
        "$\\epsilon$ | A small constant used to avoid division by zero in some calculations\n",
        "$W^{(l)}$ | The weight matrix for layer $l$\n",
        "$b^{(l)}$ | The bias vector for layer $l$\n",
        "$\\mathbf{Z}^{(l)}$ | The vector of inputs to layer $l$\n",
        "$\\mathbf{A}^{(l)}$ | The vector of activations for layer $l$\n",
        "$\\mathbf{H}^{(t)}$ | The hidden state vector of a recurrent neural network at time $t$\n",
        "$\\mathbf{W}^{(h)}$ | The weight matrix for the hidden state in a recurrent neural network\n",
        "$\\mathbf{W}^{(x)}$ | The weight matrix for the input in a recurrent neural network\n",
        "$\\mathbf{b}^{(h)}$ | The bias vector for the hidden state in a recurrent neural network\n",
        "$\\mathbf{b}^{(x)}$ | The bias vector for the input in a recurrent neural network\n"
      ],
      "metadata": {
        "id": "s-HuF9unsClF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important Equations in Machine Learning\n",
        "\n",
        "Here are some important equations in machine learning, along with a summary of each:\n",
        "\n",
        "Equation | Summary\n",
        "-------- | -------\n",
        "$\\mathbf{\\hat{y}} = H(\\mathbf{x}; \\theta)$ | This equation represents the hypothesis function, which takes input features $\\mathbf{x}$ and model parameters $\\theta$ and outputs predictions $\\mathbf{\\hat{y}}$.\n",
        "$\\mathcal{L}(\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}L(\\mathbf{\\hat{y}}^{(i)}, \\mathbf{y}^{(i)})$ | This equation represents the average loss over a dataset of size $m$, where $L(\\cdot)$ is the loss function, $\\mathbf{\\hat{y}}^{(i)}$ is the predicted output for the $i$-th data point, and $\\mathbf{y}^{(i)}$ is the actual output for the $i$-th data point.\n",
        "$\\nabla_{\\theta} \\mathcal{L}(\\theta)$ | This equation represents the gradient of the loss function with respect to the model parameters $\\theta$. It is used to update the model parameters during training.\n",
        "$\\theta_{t+1} = \\theta_{t} - \\alpha \\nabla_{\\theta} \\mathcal{L}(\\theta_t)$ | This equation represents the update rule for gradient descent, where $\\alpha$ is the learning rate and $\\theta_t$ represents the model parameters at iteration $t$.\n",
        "$\\mathbf{w} \\leftarrow \\mathbf{w} - \\alpha \\nabla_{\\mathbf{w}}\\mathcal{L}(\\mathbf{w}, b)$ | This equation represents the update rule for the weight vector $\\mathbf{w}$ in a linear regression model, where $\\alpha$ is the learning rate, $b$ is the bias term, and $\\nabla_{\\mathbf{w}}\\mathcal{L}(\\mathbf{w}, b)$ is the gradient of the loss function with respect to the weight vector.\n",
        "$\\mathbf{w} \\leftarrow \\mathbf{w} - \\alpha \\frac{1}{n}\\sum_{i=1}^{n}\\nabla_{\\mathbf{w}}\\mathcal{L}(\\mathbf{w}, \\mathbf{x}^{(i)}, y^{(i)})$ | This equation represents the update rule for the weight vector $\\mathbf{w}$ in a linear regression model using stochastic gradient descent (SGD), where $\\alpha$ is the learning rate, $n$ is the batch size, $\\mathbf{x}^{(i)}$ is the $i$-th input feature vector, $y^{(i)}$ is the corresponding target value, and $\\nabla_{\\mathbf{w}}\\mathcal{L}(\\mathbf{w}, \\mathbf{x}^{(i)}, y^{(i)})$ is the gradient of the loss function with respect to the weight vector for the $i$-th data point.\n",
        "$\\mathbf{z}^{(l)} = \\mathbf{W}^{(l)}\\mathbf{a}^{(l-1)} + \\mathbf{b}^{(l)}$ | This equation represents the linear transformation of the $l$-th layer in a neural network, where $\\math\n"
      ],
      "metadata": {
        "id": "Qtn5DPL1sITv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important Equations in Deep Learning\n",
        "\n",
        "Here are some important equations in deep learning, along with a summary of each:\n",
        "\n",
        "Equation | Summary\n",
        "-------- | -------\n",
        "$\\mathbf{z}^{(l)} = \\mathbf{W}^{(l)}\\mathbf{a}^{(l-1)} + \\mathbf{b}^{(l)}$ | This equation represents the linear transformation of the $l$-th layer in a neural network, where $\\mathbf{W}^{(l)}$ is the weight matrix, $\\mathbf{a}^{(l-1)}$ is the activation vector from the previous layer, and $\\mathbf{b}^{(l)}$ is the bias vector.\n",
        "$\\mathbf{a}^{(l)} = f(\\mathbf{z}^{(l)})$ | This equation represents the activation function applied to the output of the $l$-th layer in a neural network, where $f(\\cdot)$ is a non-linear function such as ReLU or sigmoid.\n",
        "$\\mathbf{h}_t = f(\\mathbf{W}^{(h)}\\mathbf{h}_{t-1} + \\mathbf{W}^{(x)}\\mathbf{x}_t + \\mathbf{b})$ | This equation represents the hidden state update for a recurrent neural network, where $\\mathbf{h}_t$ is the hidden state at time $t$, $\\mathbf{x}_t$ is the input at time $t$, $\\mathbf{W}^{(h)}$ is the weight matrix for the hidden state, $\\mathbf{W}^{(x)}$ is the weight matrix for the input, $\\mathbf{b}$ is the bias vector, and $f(\\cdot)$ is a non-linear activation function.\n",
        "$\\mathbf{\\hat{y}} = \\sigma(\\mathbf{W}^{(L)}\\mathbf{a}^{(L-1)} + \\mathbf{b}^{(L)})$ | This equation represents the output layer of a neural network, where $\\mathbf{W}^{(L)}$ is the weight matrix for the output layer, $\\mathbf{a}^{(L-1)}$ is the activation vector from the previous layer, $\\mathbf{b}^{(L)}$ is the bias vector, and $\\sigma(\\cdot)$ is the activation function used for binary classification (sigmoid) or multi-class classification (softmax).\n",
        "$\\mathbf{z}_{i,j} = \\sum_{k=1}^{C^{(l-1)}}\\sum_{p=0}^{F-1}\\sum_{q=0}^{F-1}\\mathbf{a}_{(i+p),(j+q),k}^{(l-1)}\\mathbf{W}_{p,q,k,j}^{(l)} + b_j^{(l)}$ | This equation represents the convolutional layer of a neural network, where $\\mathbf{a}_{(i+p),(j+q),k}^{(l-1)}$ is the activation at pixel location $(i+p, j+q)$ for channel $k$ in the previous layer, $\\mathbf{W}_{p,q,k,j}^{(l)}$ is the weight for the convolutional filter at position $(p,q)$ for channel $k$ in the current layer, $b_j^{(l)}$ is the bias for filter $j$ in the current layer\n"
      ],
      "metadata": {
        "id": "bXxY7VBBsp9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important Equations in Deep Learning\n",
        "\n",
        "Here are some important equations in deep learning, along with a summary of each:\n",
        "\n",
        "Equation                                          | Summary\n",
        "------------------------------------------------- | -------\n",
        "$\\mathbf{z}^{(l)} = \\mathbf{W}^{(l)}\\mathbf{a}^{(l-1)} + \\mathbf{b}^{(l)}$ | This equation represents the linear transformation of the $l$-th layer in a neural network, where $\\mathbf{W}^{(l)}$ is the weight matrix, $\\mathbf{a}^{(l-1)}$ is the activation vector from the previous layer, and $\\mathbf{b}^{(l)}$ is the bias vector.\n",
        "$\\mathbf{a}^{(l)} = f(\\mathbf{z}^{(l)})$         | This equation represents the activation function applied to the output of the $l$-th layer in a neural network, where $f(\\cdot)$ is a non-linear function such as ReLU or sigmoid.\n",
        "$\\mathbf{h}_t = f(\\mathbf{W}^{(h)}\\mathbf{h}_{t-1} + \\mathbf{W}^{(x)}\\mathbf{x}_t + \\mathbf{b})$ | This equation represents the hidden state update for a recurrent neural network, where $\\mathbf{h}_t$ is the hidden state at time $t$, $\\mathbf{x}_t$ is the input at time $t$, $\\mathbf{W}^{(h)}$ is the weight matrix for the hidden state, $\\mathbf{W}^{(x)}$ is the weight matrix for the input, $\\mathbf{b}$ is the bias vector, and $f(\\cdot)$ is a non-linear activation function.\n",
        "$\\mathbf{\\hat{y}} = \\sigma(\\mathbf{W}^{(L)}\\mathbf{a}^{(L-1)} + \\mathbf{b}^{(L)})$ | This equation represents the output layer of a neural network, where $\\mathbf{W}^{(L)}$ is the weight matrix for the output layer, $\\mathbf{a}^{(L-1)}$ is the activation vector from the previous layer, $\\mathbf{b}^{(L)}$ is the bias vector, and $\\sigma(\\cdot)$ is the activation function used for binary classification (sigmoid) or multi-class classification (softmax).\n",
        "$\\mathbf{z}_{i,j} = \\sum_{k=1}^{C^{(l-1)}}\\sum_{p=0}^{F-1}\\sum_{q=0}^{F-1}\\mathbf{a}_{(i+p),(j+q),k}^{(l-1)}\\mathbf{W}_{p,q,k,j}^{(l)} + b_j^{(l)}$ | This equation represents the convolutional layer of a neural network, where $\\mathbf{a}_{(i+p),(j+q),k}^{(l-1)}$ is the activation at pixel location $(i+p, j+q)$ for channel $k$ in the previous layer, $\\mathbf{W}_{p,q,k,j}^{(l)}$ is the weight for the convolutional filter at position $(p,q)$ for channel $k$ in the current layer, $b_j^{(l)}$ is the bias for filter $j\n"
      ],
      "metadata": {
        "id": "d-S762fztEBq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "f'(x) ≈ [f(x+dx) - f(x-dx)] / (2*dx)\n",
        "\n",
        "\n",
        "f'(x) ≈ [f(x+h) - f(x-h)] / (2*h)"
      ],
      "metadata": {
        "id": "-1JE31ZoyVaG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OaQl3_99719G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "i2KTIuH2wOk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def f(x):\n",
        "    return x**2\n",
        "\n",
        "x = np.linspace(0, 2, 100)\n",
        "y = f(x)\n",
        "plt.plot(x, y, label='f(x)')\n",
        "\n",
        "x0 = 1\n",
        "y0 = f(x0)\n",
        "h = 0.1\n",
        "m = (f(x0+h) - f(x0-h)) / (2*h)\n",
        "b = y0 - m*x0\n",
        "tangent = m*x + b\n",
        "plt.plot(x, tangent, label='Tangent line')\n",
        "\n",
        "plt.xlim(0, 2)\n",
        "plt.ylim(0, 4)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "\n",
        "# add slope and point of tangency annotation\n",
        "s = 'Slope: {:.2f}'.format(m)\n",
        "p = 'Point of tangency: ({:.2f}, {:.2f})'.format(x0, y0)\n",
        "plt.annotate(s, xy=(1.2, 2.5), fontsize=12)\n",
        "plt.annotate(p, xy=(1.2, 2), fontsize=12)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "2JPAneUVxkS1",
        "outputId": "a979d41f-71ef-4f65-ffd8-f2c628e37767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JMA1OLkqcLQX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}